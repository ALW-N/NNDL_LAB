{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN9Jj6pJhdU95z9EWSWLxQt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ALW-N/NNDL_LAB/blob/main/Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "IQOeEWa47S-_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeknPABbbV0x",
        "outputId": "8747fc57-52a5-46e5-e7e4-444863abb0c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert class labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional Data Augmentation"
      ],
      "metadata": {
        "id": "WqBfE-fB7YNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(x_train)\n"
      ],
      "metadata": {
        "id": "vdDfDJ0XzZsR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Network Architecture Design\n"
      ],
      "metadata": {
        "id": "FpLMNue_7btH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Flatten(input_shape=(32, 32, 3)))\n",
        "\n",
        "# Hidden layers\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Output layer with softmax activation\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "LuS3PUytze0j",
        "outputId": "34599dd5-95e7-4c68-b81e-35631dcd2c24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,573,376\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,570\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,376</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,707,274\u001b[0m (6.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,707,274</span> (6.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,707,274\u001b[0m (6.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,707,274</span> (6.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "\n",
        "\n",
        "Flatten layer: Converts the 32x32x3 input image into a 1D vector of size 3072.\n",
        "\n",
        "\n",
        "Hidden layers: Two fully connected layers with 512 and 256 neurons. The ReLU activation function is chosen to introduce non-linearity and avoid the vanishing gradient problem.\n",
        "\n",
        "Output layer: A softmax layer with 10 neurons, corresponding to the 10 classes, and it outputs the probability distribution for each class.\n",
        "\n",
        "Activation Functions:\n",
        "\n",
        "ReLU (Rectified Linear Unit): ReLU is commonly used because it helps with faster convergence and prevents vanishing gradients. It outputs a value if it's positive; otherwise, it returns zero.\n",
        "\n",
        "Tanh: Another activation function we could have used is tanh, which maps the output between -1 and 1, useful for symmetrically distributed inputs but prone to vanishing gradients."
      ],
      "metadata": {
        "id": "VcCsgI7y7fdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "GSRZPe2E8QHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "7lbGtROfzhgS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model:"
      ],
      "metadata": {
        "id": "GPzwwhqg8VSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with data augmentation\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    steps_per_epoch=len(x_train) // batch_size,\n",
        "                    epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-YL2QJHzjmy",
        "outputId": "eb63877b-39c7-4bc3-ced8-5470eb45192d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.2206 - loss: 2.1460 - val_accuracy: 0.3087 - val_loss: 1.8883\n",
            "Epoch 2/50\n",
            "\u001b[1m  1/781\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.2344 - loss: 2.1542"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.2344 - loss: 2.1542 - val_accuracy: 0.3191 - val_loss: 1.8768\n",
            "Epoch 3/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.2838 - loss: 1.9490 - val_accuracy: 0.3484 - val_loss: 1.8324\n",
            "Epoch 4/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 0.2969 - loss: 2.0116 - val_accuracy: 0.3507 - val_loss: 1.8256\n",
            "Epoch 5/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.3079 - loss: 1.8922 - val_accuracy: 0.3577 - val_loss: 1.7833\n",
            "Epoch 6/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.3125 - loss: 1.8756 - val_accuracy: 0.3560 - val_loss: 1.7838\n",
            "Epoch 7/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.3193 - loss: 1.8567 - val_accuracy: 0.3796 - val_loss: 1.7647\n",
            "Epoch 8/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.2969 - loss: 2.0395 - val_accuracy: 0.3797 - val_loss: 1.7680\n",
            "Epoch 9/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.3257 - loss: 1.8466 - val_accuracy: 0.3884 - val_loss: 1.7376\n",
            "Epoch 10/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.2188 - loss: 1.8360 - val_accuracy: 0.3930 - val_loss: 1.7304\n",
            "Epoch 11/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.3335 - loss: 1.8281 - val_accuracy: 0.3915 - val_loss: 1.7246\n",
            "Epoch 12/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.3750 - loss: 1.8566 - val_accuracy: 0.3997 - val_loss: 1.7140\n",
            "Epoch 13/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 42ms/step - accuracy: 0.3391 - loss: 1.8088 - val_accuracy: 0.4001 - val_loss: 1.7107\n",
            "Epoch 14/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.4219 - loss: 1.6837 - val_accuracy: 0.4056 - val_loss: 1.7069\n",
            "Epoch 15/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.3389 - loss: 1.8107 - val_accuracy: 0.3975 - val_loss: 1.7116\n",
            "Epoch 16/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.3750 - loss: 1.8287 - val_accuracy: 0.3976 - val_loss: 1.7131\n",
            "Epoch 17/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.3395 - loss: 1.8005 - val_accuracy: 0.4045 - val_loss: 1.6826\n",
            "Epoch 18/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 0.2812 - loss: 1.8353 - val_accuracy: 0.4063 - val_loss: 1.6830\n",
            "Epoch 19/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.3516 - loss: 1.7822 - val_accuracy: 0.4148 - val_loss: 1.6641\n",
            "Epoch 20/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.4219 - loss: 1.5793 - val_accuracy: 0.4152 - val_loss: 1.6637\n",
            "Epoch 21/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.3561 - loss: 1.7777 - val_accuracy: 0.4267 - val_loss: 1.6683\n",
            "Epoch 22/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.3750 - loss: 1.7397 - val_accuracy: 0.4245 - val_loss: 1.6735\n",
            "Epoch 23/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 44ms/step - accuracy: 0.3594 - loss: 1.7613 - val_accuracy: 0.4214 - val_loss: 1.6759\n",
            "Epoch 24/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.4219 - loss: 1.5908 - val_accuracy: 0.4233 - val_loss: 1.6721\n",
            "Epoch 25/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 45ms/step - accuracy: 0.3592 - loss: 1.7599 - val_accuracy: 0.4218 - val_loss: 1.6492\n",
            "Epoch 26/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.3750 - loss: 1.7982 - val_accuracy: 0.4231 - val_loss: 1.6528\n",
            "Epoch 27/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.3593 - loss: 1.7562 - val_accuracy: 0.4321 - val_loss: 1.6326\n",
            "Epoch 28/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.3281 - loss: 1.8334 - val_accuracy: 0.4313 - val_loss: 1.6337\n",
            "Epoch 29/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.3649 - loss: 1.7505 - val_accuracy: 0.4307 - val_loss: 1.6290\n",
            "Epoch 30/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.3594 - loss: 1.6944 - val_accuracy: 0.4278 - val_loss: 1.6340\n",
            "Epoch 31/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.3623 - loss: 1.7484 - val_accuracy: 0.4276 - val_loss: 1.6441\n",
            "Epoch 32/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.3438 - loss: 1.8348 - val_accuracy: 0.4261 - val_loss: 1.6472\n",
            "Epoch 33/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 44ms/step - accuracy: 0.3654 - loss: 1.7440 - val_accuracy: 0.4258 - val_loss: 1.6427\n",
            "Epoch 34/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.2812 - loss: 1.9219 - val_accuracy: 0.4264 - val_loss: 1.6422\n",
            "Epoch 35/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.3730 - loss: 1.7398 - val_accuracy: 0.4240 - val_loss: 1.6443\n",
            "Epoch 36/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.3438 - loss: 1.7966 - val_accuracy: 0.4237 - val_loss: 1.6436\n",
            "Epoch 37/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 44ms/step - accuracy: 0.3727 - loss: 1.7258 - val_accuracy: 0.4419 - val_loss: 1.6144\n",
            "Epoch 38/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 1.8200 - val_accuracy: 0.4434 - val_loss: 1.6132\n",
            "Epoch 39/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.3660 - loss: 1.7452 - val_accuracy: 0.4416 - val_loss: 1.6198\n",
            "Epoch 40/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.2969 - loss: 1.9250 - val_accuracy: 0.4420 - val_loss: 1.6231\n",
            "Epoch 41/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 45ms/step - accuracy: 0.3751 - loss: 1.7244 - val_accuracy: 0.4221 - val_loss: 1.6380\n",
            "Epoch 42/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.2500 - loss: 1.8771 - val_accuracy: 0.4202 - val_loss: 1.6453\n",
            "Epoch 43/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.3752 - loss: 1.7211 - val_accuracy: 0.4441 - val_loss: 1.6127\n",
            "Epoch 44/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 0.4375 - loss: 1.6196 - val_accuracy: 0.4434 - val_loss: 1.6139\n",
            "Epoch 45/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.3759 - loss: 1.7160 - val_accuracy: 0.4292 - val_loss: 1.6263\n",
            "Epoch 46/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.3594 - loss: 1.7820 - val_accuracy: 0.4310 - val_loss: 1.6227\n",
            "Epoch 47/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.3797 - loss: 1.7167 - val_accuracy: 0.4502 - val_loss: 1.5984\n",
            "Epoch 48/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 0.4219 - loss: 1.5701 - val_accuracy: 0.4466 - val_loss: 1.5990\n",
            "Epoch 49/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.3819 - loss: 1.7057 - val_accuracy: 0.4297 - val_loss: 1.6238\n",
            "Epoch 50/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.3281 - loss: 1.7374 - val_accuracy: 0.4295 - val_loss: 1.6237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation:\n"
      ],
      "metadata": {
        "id": "t7y9dnnM8aQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "# Confusion matrix, precision, recall, F1-score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "y_pred = np.argmax(model.predict(x_test), axis=-1)\n",
        "y_true = np.argmax(y_test, axis=-1)\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWiGWN8pzmJ9",
        "outputId": "943a4d9b-bc5b-4774-d32c-dd110239b930"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4277 - loss: 1.6273\n",
            "Test accuracy: 0.429500013589859\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "[[345  45  97  41  21   5  38 101 115 192]\n",
            " [ 12 452  29  34  10  20  40  45  19 339]\n",
            " [ 51  25 281  85 168  37 171 135  15  32]\n",
            " [  3   9  88 232  83 165 238 103  18  61]\n",
            " [ 27   7 132  50 394  16 178 143  17  36]\n",
            " [  4   7 101 157 100 298 167 111  17  38]\n",
            " [  2   5  76  73 129  30 609  41   7  28]\n",
            " [  8  19  52  47  86  44  70 567   7 100]\n",
            " [ 53  75  21  40  21  23  29  23 449 266]\n",
            " [  9 123  11  38  12  12  48  62  17 668]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.34      0.46      1000\n",
            "           1       0.59      0.45      0.51      1000\n",
            "           2       0.32      0.28      0.30      1000\n",
            "           3       0.29      0.23      0.26      1000\n",
            "           4       0.38      0.39      0.39      1000\n",
            "           5       0.46      0.30      0.36      1000\n",
            "           6       0.38      0.61      0.47      1000\n",
            "           7       0.43      0.57      0.49      1000\n",
            "           8       0.66      0.45      0.53      1000\n",
            "           9       0.38      0.67      0.48      1000\n",
            "\n",
            "    accuracy                           0.43     10000\n",
            "   macro avg       0.46      0.43      0.42     10000\n",
            "weighted avg       0.46      0.43      0.42     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization Strategies:"
      ],
      "metadata": {
        "id": "BQaR8lSZ8eat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "\n",
        "# Train with callbacks\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    steps_per_epoch=len(x_train) // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[early_stopping, lr_scheduler])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOIg2la-66aV",
        "outputId": "46e6dce4-a106-453d-c9c8-51d891da2ea0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 57ms/step - accuracy: 0.3822 - loss: 1.7079 - val_accuracy: 0.4365 - val_loss: 1.6111 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m  1/781\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2969 - loss: 1.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.2969 - loss: 1.6712 - val_accuracy: 0.4385 - val_loss: 1.6082 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 54ms/step - accuracy: 0.3796 - loss: 1.6980 - val_accuracy: 0.4475 - val_loss: 1.6017 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.4375 - loss: 1.5108 - val_accuracy: 0.4463 - val_loss: 1.6060 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 45ms/step - accuracy: 0.3857 - loss: 1.6985 - val_accuracy: 0.4357 - val_loss: 1.5976 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.3906 - loss: 1.7101 - val_accuracy: 0.4370 - val_loss: 1.5982 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 48ms/step - accuracy: 0.3861 - loss: 1.6957 - val_accuracy: 0.4440 - val_loss: 1.5910 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.2812 - loss: 1.8850 - val_accuracy: 0.4466 - val_loss: 1.5923 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 45ms/step - accuracy: 0.3878 - loss: 1.6957 - val_accuracy: 0.4396 - val_loss: 1.6112 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.3594 - loss: 1.7268 - val_accuracy: 0.4407 - val_loss: 1.6092 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.3886 - loss: 1.6920 - val_accuracy: 0.4383 - val_loss: 1.5937 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.3750 - loss: 1.6456 - val_accuracy: 0.4377 - val_loss: 1.5940 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 50ms/step - accuracy: 0.4041 - loss: 1.6512 - val_accuracy: 0.4693 - val_loss: 1.5489 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.4688 - loss: 1.5664 - val_accuracy: 0.4688 - val_loss: 1.5491 - learning_rate: 1.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 45ms/step - accuracy: 0.4076 - loss: 1.6351 - val_accuracy: 0.4699 - val_loss: 1.5482 - learning_rate: 1.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.5625 - loss: 1.4922 - val_accuracy: 0.4701 - val_loss: 1.5481 - learning_rate: 1.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.4055 - loss: 1.6355 - val_accuracy: 0.4683 - val_loss: 1.5511 - learning_rate: 1.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.4219 - loss: 1.6944 - val_accuracy: 0.4681 - val_loss: 1.5514 - learning_rate: 1.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 45ms/step - accuracy: 0.4117 - loss: 1.6279 - val_accuracy: 0.4677 - val_loss: 1.5562 - learning_rate: 1.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.4844 - loss: 1.5247 - val_accuracy: 0.4677 - val_loss: 1.5565 - learning_rate: 1.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.4143 - loss: 1.6292 - val_accuracy: 0.4719 - val_loss: 1.5371 - learning_rate: 1.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.5000 - loss: 1.3689 - val_accuracy: 0.4718 - val_loss: 1.5368 - learning_rate: 1.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 44ms/step - accuracy: 0.4123 - loss: 1.6310 - val_accuracy: 0.4742 - val_loss: 1.5357 - learning_rate: 1.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 0.2969 - loss: 1.7652 - val_accuracy: 0.4746 - val_loss: 1.5361 - learning_rate: 1.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.4164 - loss: 1.6235 - val_accuracy: 0.4711 - val_loss: 1.5389 - learning_rate: 1.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.4062 - loss: 1.5598 - val_accuracy: 0.4715 - val_loss: 1.5387 - learning_rate: 1.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.4138 - loss: 1.6235 - val_accuracy: 0.4739 - val_loss: 1.5352 - learning_rate: 1.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.3906 - loss: 1.5896 - val_accuracy: 0.4743 - val_loss: 1.5353 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 45ms/step - accuracy: 0.4156 - loss: 1.6204 - val_accuracy: 0.4721 - val_loss: 1.5380 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.4844 - loss: 1.5607 - val_accuracy: 0.4721 - val_loss: 1.5383 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 44ms/step - accuracy: 0.4116 - loss: 1.6197 - val_accuracy: 0.4749 - val_loss: 1.5433 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.2969 - loss: 1.7622 - val_accuracy: 0.4750 - val_loss: 1.5428 - learning_rate: 1.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 46ms/step - accuracy: 0.4242 - loss: 1.6048 - val_accuracy: 0.4753 - val_loss: 1.5345 - learning_rate: 1.0000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.4375 - loss: 1.6718 - val_accuracy: 0.4751 - val_loss: 1.5345 - learning_rate: 1.0000e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - accuracy: 0.4190 - loss: 1.6157 - val_accuracy: 0.4734 - val_loss: 1.5351 - learning_rate: 1.0000e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.3750 - loss: 1.7503 - val_accuracy: 0.4735 - val_loss: 1.5351 - learning_rate: 1.0000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 48ms/step - accuracy: 0.4167 - loss: 1.6100 - val_accuracy: 0.4730 - val_loss: 1.5331 - learning_rate: 1.0000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.4688 - loss: 1.4968 - val_accuracy: 0.4729 - val_loss: 1.5331 - learning_rate: 1.0000e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 47ms/step - accuracy: 0.4182 - loss: 1.6163 - val_accuracy: 0.4742 - val_loss: 1.5331 - learning_rate: 1.0000e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.5000 - loss: 1.5552 - val_accuracy: 0.4742 - val_loss: 1.5331 - learning_rate: 1.0000e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 47ms/step - accuracy: 0.4180 - loss: 1.6130 - val_accuracy: 0.4751 - val_loss: 1.5328 - learning_rate: 1.0000e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.4219 - loss: 1.5337 - val_accuracy: 0.4751 - val_loss: 1.5328 - learning_rate: 1.0000e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.4185 - loss: 1.6121 - val_accuracy: 0.4760 - val_loss: 1.5319 - learning_rate: 1.0000e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 0.4688 - loss: 1.6294 - val_accuracy: 0.4758 - val_loss: 1.5319 - learning_rate: 1.0000e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.4154 - loss: 1.6142 - val_accuracy: 0.4780 - val_loss: 1.5317 - learning_rate: 1.0000e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.3906 - loss: 1.5931 - val_accuracy: 0.4779 - val_loss: 1.5317 - learning_rate: 1.0000e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.4163 - loss: 1.6204 - val_accuracy: 0.4766 - val_loss: 1.5323 - learning_rate: 1.0000e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.3906 - loss: 1.5697 - val_accuracy: 0.4768 - val_loss: 1.5323 - learning_rate: 1.0000e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 53ms/step - accuracy: 0.4192 - loss: 1.6108 - val_accuracy: 0.4757 - val_loss: 1.5323 - learning_rate: 1.0000e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 0.4375 - loss: 1.6631 - val_accuracy: 0.4756 - val_loss: 1.5323 - learning_rate: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eXLRvDKeA_Rm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}